# Data Science & Machine Learning

This directory contains example notebooks, scripts, and utilities that demonstrate practical data science and machine learning workflows â€” from data ingestion and exploratory analysis to feature engineering, model training, evaluation, and simple deployment examples. Use the notebooks for interactive exploration and the src files for reusable components and experiments.

## Overview
Data Science is the practice of extracting insights and value from data using statistics, visualization, and engineering. Machine Learning (ML) is a subfield that builds models to make predictions or discover patterns from data. Together they power data-driven applications across industries.

## Core Concepts
- Data: structured and unstructured sources (CSV, databases, images, text, time series).
- Statistics: descriptive stats, probability, hypothesis testing.
- Feature engineering: cleaning, transforming, and encoding raw data for models.
- Models: algorithms that learn patterns (supervised, unsupervised, reinforcement).
- Evaluation: metrics (accuracy, precision/recall, F1, ROC-AUC, RMSE) and validation strategies (train/test split, cross-validation).
- Deployment: serving models in production, monitoring performance and drift.

## Types of Machine Learning
- Supervised learning: regression and classification (labels available).
- Unsupervised learning: clustering and dimensionality reduction (no labels).
- Reinforcement learning: agents learn via rewards and environment interactions.
- Semi-supervised & self-supervised techniques for limited labelled data.

## Typical Workflow
1. Define the problem and success metric.
2. Acquire and explore data (EDA).
3. Clean and preprocess (missing values, normalization, encoding).
4. Feature engineering and selection.
5. Train multiple models and tune hyperparameters.
6. Evaluate using appropriate metrics and validation.
7. Deploy the chosen model and monitor in production.
8. Iterate and maintain datasets and models.

## Common Algorithms & Techniques
- Linear / Logistic Regression
- Decision Trees, Random Forests, Gradient Boosting (XGBoost, LightGBM)
- Support Vector Machines (SVM)
- k-Means, Hierarchical Clustering
- Principal Component Analysis (PCA)
- Neural Networks and Deep Learning (CNNs, RNNs/Transformers)
- Time series methods (ARIMA, Prophet)

## Tools & Libraries (Python ecosystem)
- Data manipulation: NumPy, pandas
- Visualization: Matplotlib, Seaborn, Plotly
- ML & modeling: scikit-learn, XGBoost, LightGBM
- Deep learning: TensorFlow, Keras, PyTorch
- Notebooks & environment: Jupyter, VS Code, conda/venv
- Experiment tracking & MLOps: MLflow, Weights & Biases, Docker, Kubernetes
